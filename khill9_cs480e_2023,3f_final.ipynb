{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LadyLandshark/Annoyatron/blob/master/khill9_cs480e_2023%2C3f_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CS480E/580E: Final Exam\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NVU1oJYOZ4RI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Instructions\n",
        "### Due December 13th, 11:59 PM.\n",
        "\n",
        "In the final exam, you will use autoencoders to do dimensionality reduction on the MNIST images. You will then use the reduced dimensional representations to perform similarity search on test images. At the end of notebook, you will be able to retrieve k-most similar images on the training set.  \n",
        "\n",
        "\n",
        "Functions and cells that need to be implemented are marked with a bold **implement** keyword or clearly marked in the experiments section.\n",
        "\n",
        "Make sure to **run** the cells marked for running to make sure all the data and functions are available.\n"
      ],
      "metadata": {
        "id": "wl3YVu4ZFABa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8Xtjmf2iZ0g3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import torchvision.datasets as dset\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# for plotting\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['font.size'] = 16\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "You will be working on the MNIST dataset, which is 60,000 training and 10,000 test images. Each picture contains a centered image of white digit on black background (0 through 9).\n",
        "\n",
        "To simplify our code here, use the PyTorch MNIST wrapper, which downloads and loads the MNIST dataset. See the [documentation](https://github.com/pytorch/vision/blob/master/torchvision/datasets/mnist.py) for more information about the interface. The default parameters will take 5,000 of the training examples and place them into a validation dataset. The data will be saved into a folder called `MNIST_data`.\n",
        "\n",
        "**Run** the following cell to mount your drive on colab."
      ],
      "metadata": {
        "id": "xfi1dtm9F-WG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o7LzaKFO3YEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f8e8a2-a3ba-4dff-f0bb-741b080e9ca4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cells to retrieve the MNIST training, validation, and test sets"
      ],
      "metadata": {
        "id": "JMhyPVyA4irk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dset.MNIST('./MNIST_data', train=True, download=True,\n",
        "                           transform=T.ToTensor())\n",
        "\n",
        "mnist_test = dset.MNIST('./MNIST_data', train=False, download=True,\n",
        "                        transform=T.ToTensor())\n",
        "\n",
        "mnist_train, mnist_validation = random_split(mnist_train, [.8, .2])"
      ],
      "metadata": {
        "id": "AZUtLcYC3aU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6111165-bc11-43a1-bd7c-d094ba6fd4b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 54233763.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 71847979.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 31210868.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2576833.32it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** this cell to print the number of cells on the traning, validation, and test datasets."
      ],
      "metadata": {
        "id": "TvKznGC14v_I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(mnist_train), len(mnist_validation), len(mnist_test))"
      ],
      "metadata": {
        "id": "5mtDzRQ3aKtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e5e5faa-10d4-41f4-8edc-01ace8334460"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48000 12000 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** this cell to define the helper function to generate grids of images."
      ],
      "metadata": {
        "id": "BkemVCHR4u4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images):\n",
        "    images = torch.reshape(\n",
        "        images, [images.shape[0], -1]\n",
        "    )  # images reshape to (batch_size, D)\n",
        "    sqrtn = int(math.ceil(math.sqrt(images.shape[0])))\n",
        "    sqrtimg = int(math.ceil(math.sqrt(images.shape[1])))\n",
        "\n",
        "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
        "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis(\"off\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect(\"equal\")\n",
        "        plt.imshow(img.reshape([sqrtimg, sqrtimg]))\n",
        "    return"
      ],
      "metadata": {
        "id": "vRV_XaaN3fzC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to define a `batch_size`, `loader_train`, and `loader_validation`.\n",
        "\n",
        "`batch_size` should be an integer value that defines the number of samples per mini-batch that will be used for the training dataloader.\n",
        "\n",
        "`loader_train` should be a PyTorch DataLoader on the `mnist_train` dataset with `batch_size = batch_size`, `shuffle` enabled and drop the last mini-batch.\n",
        "\n",
        "`loader_validation` should be a PyTorch DataLoader on the `mnist_validation` dataset. Set the `batch_size` as high as possible for this."
      ],
      "metadata": {
        "id": "cZ7eSC02Hnkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BEGIN SOLUTION CODE ====\n",
        "batch_size = 128\n",
        "loader_train = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "loader_validation = DataLoader(mnist_validation, batch_size=len(mnist_validation))\n",
        "# ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "3yWKhZSIHnzb"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to show an example of a grid of MNIST images."
      ],
      "metadata": {
        "id": "_Ck6ToupcrH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imgs = next(iter(loader_train))[0].view(batch_size, 784)\n",
        "show_images(imgs[:36])\n",
        "print(np.sqrt(784))"
      ],
      "metadata": {
        "id": "TeOLsn2D37Ej",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "outputId": "2038f86e-030a-44e2-9de9-18b48c2431a0"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 36 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Part 1) Autoencoder - 60 pts\n",
        "\n",
        "In the next cell, **implement** the definition of the `AutoEncoder` class, that implements an autoencoder using convolutions, transpose convolutions, fully connected and non-linear activation layers.\n",
        "\n",
        "\n",
        "\n",
        "You are free to choose any architecture you would like.\n",
        "**But your network must use at least 1 convolution layer**\n",
        "\n",
        "\n",
        "Complete the following methods:\n",
        "\n",
        "- `__init__(height, width, latent_dim)`: Initializes the desired layer and architecture.\n",
        "  - The inputs to the class constructor are:\n",
        "    - `height`: The height of the input images\n",
        "    - `width`: The width of the input images\n",
        "    - `latent_dim`: The size of the latent vector\n",
        "- `encode(x)`: Encodes a batch of images `x` to a batch of latent vectors, `h`\n",
        "- `decode(h)`: Decodes a batch of latent vectors `h` to a batch images, `x_reconstructed`\n",
        "- `forward(x)`: Uses `encode` and `decode` method to compress and reconstruct a batch of images, `x`."
      ],
      "metadata": {
        "id": "zwZIkT7VHunv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, height, width, latent_dim):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        self.latent_dim = latent_dim\n",
        "        self.layer_map = {\n",
        "            'conv1' : nn.Conv2d(1, 8, 3),\n",
        "            'relu1' : nn.ReLU(),\n",
        "            'pool1' : nn.MaxPool2d(2, return_indices=True),\n",
        "            'conv2' : nn.Conv2d(8, 16, 3),\n",
        "            'relu2' : nn.ReLU(),\n",
        "            'pool2' : nn.MaxPool2d(2, return_indices=True),\n",
        "            'flatten': nn.Flatten(),\n",
        "            'linear': nn.Linear(400, self.latent_dim),\n",
        "            'relu_final': nn.ReLU()\n",
        "        }\n",
        "        self.layers = nn.ModuleList(self.layer_map.values())\n",
        "        #self.parameters = nn.ParameterList([self.height, self.width, self.latent_dim])\n",
        "\n",
        "\n",
        "\n",
        "        # ==== END SOLUTION CODE ====\n",
        "    def encode(self, x):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        h = None\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        #print(f'X shape: {x.shape}')\n",
        "        conv1 = self.layer_map['conv1'](x)\n",
        "        relu1 = self.layer_map['relu1'](conv1)\n",
        "        #print(f\"Relu1 shape: {relu1.shape}\")\n",
        "        (pool1, self.indices1) = self.layer_map['pool1'](relu1)\n",
        "        self.outsize1 = relu1.size()\n",
        "        relu2 = self.layer_map['relu2'](pool1)\n",
        "        conv2 = self.layer_map['conv2'](relu2)\n",
        "        (pool2, self.indices2) = self.layer_map['pool2'](conv2)\n",
        "        self.outsize2 = conv2.size()\n",
        "        flattened = self.layer_map['flatten'](pool2)\n",
        "        linear = self.layer_map['linear'](flattened)\n",
        "        h = self.layer_map['relu_final'](linear)\n",
        "\n",
        "        # ==== END SOLUTION CODE ====\n",
        "        return h\n",
        "\n",
        "    def decode(self, h):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        x_reconstructed = None\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        data_shape = h.shape\n",
        "        #print(f\"H shape: {h.shape}\")\n",
        "        #reshaped = torch.reshape(h, (self.height, self.width))\n",
        "\n",
        "        decode_layers = [\n",
        "            nn.Linear(self.latent_dim, 400),\n",
        "            nn.Unflatten(1, (16, 5, 5)),\n",
        "            nn.MaxUnpool2d(2),\n",
        "            nn.ConvTranspose2d(16, 8, 3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxUnpool2d(2),\n",
        "            nn.ConvTranspose2d(8, 1, 3),\n",
        "            nn.ReLU(),\n",
        "            #nn.BatchNorm2d(1)\n",
        "        ]\n",
        "        curr_out = h\n",
        "        for i, layer in enumerate(decode_layers):\n",
        "          if i == 2:\n",
        "            #print(f\"{curr_out.shape}, {self.indices2.shape}\")\n",
        "            curr_out = layer(curr_out, self.indices2, self.outsize2)\n",
        "          elif i == 5:\n",
        "            curr_out = layer(curr_out, self.indices1, self.outsize1)\n",
        "          else:\n",
        "            curr_out = layer(curr_out)\n",
        "\n",
        "        x_reconstructed = curr_out\n",
        "        # ==== END SOLUTION CODE ====\n",
        "        return x_reconstructed\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        x_reconstructed = None\n",
        "        # ==== BEGIN SOLUTION CODE ====\n",
        "        encoded = self.encode(x)\n",
        "        x_reconstructed = self.decode(encoded)\n",
        "        # ==== END SOLUTION CODE ====\n",
        "        return x_reconstructed"
      ],
      "metadata": {
        "id": "W9z_1RRt3_sk"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder Training\n",
        "\n",
        "In the following cell, define an autoencoder (AE) and train on the training set.\n",
        "\n",
        "The AE training algorithm is as follows:\n",
        "\n",
        "1. Instantiate an `AutoEncoder`\n",
        "2. Define an optimizer for your AE\n",
        "3. For each batch of data in `loader_train`:\n",
        "    - Pass the input through the AE to get the reconstructed input\n",
        "    - Calculate the loss using the [`nn.functional.binary_cross_entropy`](https://pytorch.org/docs/stable/generated/torch.nn.functional.binary_cross_entropy.html)\n",
        "    - Zero the gradients, propagate the loss backwards, and update the  weights using the optimizer\n",
        "\n",
        "4. Repeat 3\n",
        "5. After N iterations (or every epoch), compute the validation loss over the validation set (using the `loader_validation`).\n"
      ],
      "metadata": {
        "id": "UGxY6-fS5-Qc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder(28,28,784) # Instantiate your model to this variable\n",
        "\n",
        "# ==== BEGIN SOLUTION CODE ====\n",
        "learning_rate = 1e-3\n",
        "epochs = 3\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "for epoch in range(epochs):\n",
        "  # train\n",
        "  model.train()\n",
        "  for batch, (x, y) in enumerate(loader_train, 0):\n",
        "    reconstructed = model.forward(x)\n",
        "    if torch.max(reconstructed) > 1:\n",
        "      print(reconstructed)\n",
        "    loss = nn.functional.binary_cross_entropy(reconstructed, x)\n",
        "    #print('bob')\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "  # test\n",
        "  model.eval()\n",
        "  size = len(loader_validation.dataset)\n",
        "  num_batches = len(loader_validation)\n",
        "  validation_loss = 0\n",
        "  for batch, (x, y) in enumerate(loader_validation):\n",
        "    reconstructed = model.forward(x)\n",
        "    loss = nn.functional.binary_cross_entropy(reconstructed, x)\n",
        "    validation_loss += loss.item()\n",
        "  validation_loss /= num_batches\n",
        "  print(f\"Validation Loss  = {validation_loss}\")\n",
        "\n",
        "\n",
        "\n",
        "# ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "aKoxFGZb59FS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1adced7f-0bf0-4f31-a75f-f1762ef00aca"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0.2858, 0.3052, 0.3436,  ..., 0.2521, 0.3034, 0.2750],\n",
            "          [0.2520, 0.3736, 0.3141,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2297, 0.1715, 0.2811,  ..., 0.1853, 0.3164, 0.2750],\n",
            "          ...,\n",
            "          [0.2400, 0.3441, 0.2717,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2419, 0.2082, 0.2548,  ..., 0.2082, 0.2879, 0.2750],\n",
            "          [0.2750, 0.2750, 0.2750,  ..., 0.2750, 0.2750, 0.2750]]],\n",
            "\n",
            "\n",
            "        [[[0.2999, 0.2599, 0.2892,  ..., 0.2521, 0.3034, 0.2750],\n",
            "          [0.2472, 0.4397, 0.3179,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2613, 0.1505, 0.2052,  ..., 0.1853, 0.3164, 0.2750],\n",
            "          ...,\n",
            "          [0.2400, 0.3441, 0.2717,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2419, 0.2082, 0.2548,  ..., 0.2082, 0.2879, 0.2750],\n",
            "          [0.2750, 0.2750, 0.2750,  ..., 0.2750, 0.2750, 0.2750]]],\n",
            "\n",
            "\n",
            "        [[[0.3002, 0.2629, 0.2917,  ..., 0.2521, 0.3034, 0.2750],\n",
            "          [0.2490, 0.4427, 0.3207,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2603, 0.1513, 0.2039,  ..., 0.1853, 0.3164, 0.2750],\n",
            "          ...,\n",
            "          [0.2400, 0.3441, 0.2717,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2419, 0.2082, 0.2548,  ..., 0.2082, 0.2879, 0.2750],\n",
            "          [0.2750, 0.2750, 0.2750,  ..., 0.2750, 0.2750, 0.2750]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[0.2864, 0.3045, 0.3081,  ..., 0.2521, 0.3034, 0.2750],\n",
            "          [0.2644, 0.3901, 0.3661,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2349, 0.1507, 0.2474,  ..., 0.1853, 0.3164, 0.2750],\n",
            "          ...,\n",
            "          [0.2400, 0.3441, 0.2717,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2419, 0.2082, 0.2548,  ..., 0.2082, 0.2879, 0.2750],\n",
            "          [0.2750, 0.2750, 0.2750,  ..., 0.2750, 0.2750, 0.2750]]],\n",
            "\n",
            "\n",
            "        [[[0.2885, 0.2555, 0.2591,  ..., 0.2521, 0.3034, 0.2750],\n",
            "          [0.2510, 0.3713, 0.3168,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2795, 0.1969, 0.2773,  ..., 0.1853, 0.3164, 0.2750],\n",
            "          ...,\n",
            "          [0.2400, 0.3441, 0.2717,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2419, 0.2082, 0.2548,  ..., 0.2082, 0.2879, 0.2750],\n",
            "          [0.2750, 0.2750, 0.2750,  ..., 0.2750, 0.2750, 0.2750]]],\n",
            "\n",
            "\n",
            "        [[[0.2941, 0.2564, 0.2896,  ..., 0.2521, 0.3034, 0.2750],\n",
            "          [0.2508, 0.4215, 0.3083,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2581, 0.1644, 0.2117,  ..., 0.1853, 0.3164, 0.2750],\n",
            "          ...,\n",
            "          [0.2400, 0.3441, 0.2717,  ..., 0.3441, 0.3067, 0.2750],\n",
            "          [0.2419, 0.2082, 0.2548,  ..., 0.2082, 0.2879, 0.2750],\n",
            "          [0.2750, 0.2750, 0.2750,  ..., 0.2750, 0.2750, 0.2750]]]],\n",
            "       grad_fn=<ReluBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-195-247e85b290cf>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconstructed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0;31m#print('bob')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3120\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3122\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to generate 36 random reconstructions from your previously trained AE model and visualize the outputs."
      ],
      "metadata": {
        "id": "4cxGWAFrxumZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "# ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "pXyDl3Jg6kRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# (Part 2, 40 pts Extra Credit) Similarity Search\n",
        "\n",
        "Now using your trained model, you will generate latent vectors of the training images. This will encode the images into a vector.\n",
        "\n",
        "You will also use your trained models to encode a test image into a vector, compute a similarity measure ($L_2$ or Cosine-similarity) with the training latent vectors."
      ],
      "metadata": {
        "id": "-o27ZbMwHZl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following cell to complete the `generate_latent_vectors` function.\n",
        "\n",
        "The arguments are:\n",
        "\n",
        "- `model`: The model used to generate the latent encodings\n",
        "- `dataset`: The dataset to the generate the latent encodings\n",
        "\n",
        "Returns:\n",
        "- PyTorch tensor of latent vectors computed from the dataset images using the model. It should be a 2D tensor with `len(dataset)` rows and `latent_dim` columns.\n",
        "\n",
        "Iterate over each image in the `dataset` and `encode` the images using the `model`. Make sure to turn off backprop and gradient calculations using `with torch.no_grad()` and set the model to evaluation mode using `model.eval()`.\n",
        "\n",
        "You may find the `torch.vstack` function useful."
      ],
      "metadata": {
        "id": "iu7EbzxPxx9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_latent_vectors(model, dataset):\n",
        "    '''\n",
        "    Iterates over the dataset and uses the model to generates latent vectors.\n",
        "    Returns a Torch tensor of latent vectors of shape\n",
        "\n",
        "    Args:\n",
        "      - model : trained model\n",
        "      - dataset: PyTorch dataset of images\n",
        "\n",
        "    Returns:\n",
        "      - latent_vectors - Torch tensor of dimension (len(dataset), latent_dim).\n",
        "    '''\n",
        "    latent_vectors = None\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ====\n",
        "    return latent_vectors"
      ],
      "metadata": {
        "id": "N4d3UPbHXNvY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to generate the latent vectors of the images from the `mnist_train` dataset using your `model` and the `generate_latent_vectors` dataset."
      ],
      "metadata": {
        "id": "ZWPMyTjjwueQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_vectors = generate_latent_vectors(model, mnist_train)"
      ],
      "metadata": {
        "id": "gqG7afFMc0KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the `cosine_sim` function that computes the cosine similarity between each row of input tensors `a` and `b` and the 1-D tensor of indices with the of the `k` closest values.\n",
        "\n",
        "\n",
        "*Hint: You can use the [torch.nn.functional.cosine_similarity](https://pytorch.org/docs/stable/generated/torch.nn.functional.cosine_similarity.html#torch.nn.functional.cosine_similarity) and\n",
        "[torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html) functions. Make sure you use the appropriate parameters*  "
      ],
      "metadata": {
        "id": "37XT_cLIYVTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(a, b, k=5):\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "UCUKPmZ6d1r8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the `l2_pairwise_dist` function that computes the l2 distance between each row of input tensors `a` and `b` and returns the 1-D tensor of indices with the of the `k` closest values.\n",
        "\n",
        "*Hint: You can use the [torch.nn.functional.pairwise_distance](https://pytorch.org/docs/stable/generated/torch.nn.functional.pairwise_distance.html#torch.nn.functional.pairwise_distance) and\n",
        "[torch.topk](https://pytorch.org/docs/stable/generated/torch.topk.html) functions. Make sure you use the appropriate parameters*"
      ],
      "metadata": {
        "id": "j64XVqn7imro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def l2_pairwise_dist(a, b, k=5):\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ===="
      ],
      "metadata": {
        "id": "lCu5P2t9d3Wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Implement** the following function to find the top-k most similar images for a given image using a given 2-D array of latent vectors.\n",
        "\n",
        "The arguments are:\n",
        "  - `img`: The image to search similar images for.\n",
        "  - `model`: The trained model to use to generate latent vector of `img`.\n",
        "  - `latents`: The 2D tensor of latent vectors of the training dataset. Find the similar vectors to `img`s latent vector within this 2D tensor.\n",
        "  - `k`: The number of indices to return (default: 5)\n",
        "  - `distance_function`: The distance function to use to measure the similarity between latent vectors.  \n",
        "  \n",
        "\n",
        "Returns:\n",
        "    - The 1-D tensor of indices of the similar images to `img`\n",
        "\n",
        "\n",
        "Get the latent vector of `img` using your `model`s `encode` and then use the `distance_function` to get the `k`-nearest vectors."
      ],
      "metadata": {
        "id": "1X7NH7cwLM_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_top_k(img, model, latents, k = 5, distance_function=cosine_sim):\n",
        "    ind = None\n",
        "    # ==== BEGIN SOLUTION CODE ====\n",
        "\n",
        "    # ==== END SOLUTION CODE ====\n",
        "    return ind"
      ],
      "metadata": {
        "id": "Q1E1BdNwfbNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to define the top-k image visualization helper function."
      ],
      "metadata": {
        "id": "FnR1cK8huvdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_top_k_images(root_image, images):\n",
        "\n",
        "    num_images = len(images) + 1\n",
        "    sqrtimg = int(math.ceil(math.sqrt(28)))\n",
        "\n",
        "    fig = plt.figure(figsize=(num_images*2.5, num_images*5))\n",
        "    gs = gridspec.GridSpec(1, num_images)\n",
        "    gs.update(wspace=0.05, hspace=0.05)\n",
        "    images = [root_image] + images\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "\n",
        "        ax = plt.subplot(gs[i])\n",
        "        plt.axis(\"off\")\n",
        "        ax.set_xticklabels([])\n",
        "        ax.set_yticklabels([])\n",
        "        ax.set_aspect(\"equal\")\n",
        "        plt.imshow(img.reshape([28, 28]))\n",
        "        if i == 0:\n",
        "            ax.set_title(\"Search Image\")\n",
        "    return"
      ],
      "metadata": {
        "id": "rXfiWm3QoxVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to get the 5 most similar images to an image from the test set using a cosine similarity metric.\n",
        "\n",
        "If all the above cells are completed correctly, there should be no errors, and the found images should look visually similar."
      ],
      "metadata": {
        "id": "nF5Ttbiyu3B-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_img_ind = 19\n",
        "root_img = mnist_test[root_img_ind][0]\n",
        "_inds = find_top_k(root_img, model, training_vectors, k=5, distance_function= cosine_sim)\n",
        "images = []\n",
        "for i in _inds:\n",
        "    images.append(mnist_train[i][0])\n",
        "show_top_k_images(root_img, images)"
      ],
      "metadata": {
        "id": "NBd2UG6dnNgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run** the following cell to get the 5 most similar images to an image from the test set using a $\\mathcal{l}_2$ distance.\n",
        "\n",
        "\n",
        "If all the above cells are completed correctly, there should be no errors, and the found images should look visually similar."
      ],
      "metadata": {
        "id": "duLY_18Usuts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_img_ind = 19\n",
        "root_img = mnist_test[root_img_ind][0]\n",
        "_inds = find_top_k(root_img, model, training_vectors, k=5, distance_function=l2_pairwise_dist)\n",
        "images = []\n",
        "for i in _inds:\n",
        "    images.append(mnist_train[i][0])\n",
        "show_top_k_images(root_img, images)"
      ],
      "metadata": {
        "id": "fp5XZXdUnTVe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}